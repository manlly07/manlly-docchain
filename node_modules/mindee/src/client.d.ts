/// <reference types="node" />
/// <reference types="node" />
import { Readable } from "stream";
import { InputSource, PageOptions } from "./input";
import { Endpoint } from "./http";
import { Inference, AsyncPredictResponse, StringDict, PredictResponse } from "./parsing/common";
export interface PredictOptions {
    endpointName?: string;
    accountName?: string;
    endpointVersion?: string;
    endpoint?: Endpoint;
    /**
     * Whether to include the full text for each page.
     *
     * This performs a full OCR operation on the server and will increase response time.
     */
    allWords?: boolean;
    /**
     * Whether to include cropper results for each page.
     *
     * This performs a cropping operation on the server and will increase response time.
     */
    cropper?: boolean;
    pageOptions?: PageOptions;
}
export interface CustomConfigParams {
    /** Your organization's username on the API Builder. */
    accountName: string;
    /** The "API name" field in the "Settings" page of the API Builder. */
    endpointName: string;
    /**
     * If set, locks the version of the model to use.
     * If not set, use the latest version of the model.
     */
    version?: string;
}
export interface ClientOptions {
    /** Your API key for all endpoints. */
    apiKey?: string;
    /** Raise an `Error` on errors. */
    throwOnError?: boolean;
    /** Log debug messages. */
    debug?: boolean;
}
/**
 * Mindee Client
 */
export declare class Client {
    #private;
    protected apiKey: string;
    /**
     * @param options
     */
    constructor({ apiKey, throwOnError, debug }?: ClientOptions);
    /**
     * Send a document to a synchronous endpoint and parse the predictions.
     * @param productClass
     * @param params
     */
    parse<T extends Inference>(productClass: new (httpResponse: StringDict) => T, inputSource: InputSource, params?: PredictOptions): Promise<PredictResponse<T>>;
    /**
     * Send the document to an asynchronous endpoint and return its ID in the queue.
     * @param productClass
     * @param params
     */
    enqueue<T extends Inference>(productClass: new (httpResponse: StringDict) => T, inputSource: InputSource, params?: PredictOptions): Promise<AsyncPredictResponse<T>>;
    parseQueued<T extends Inference>(productClass: new (httpResponse: StringDict) => T, queueId: string, params?: PredictOptions): Promise<AsyncPredictResponse<T>>;
    protected getBooleanParam(param?: boolean): boolean;
    /**
     * Creates a custom endpoint with the given values. Raises an error if the endpoint is invalid.
     * @param productClass Class of the product
     * @param endpointName Name of a custom Endpoint
     * @param accountName Name of the account tied to the active Endpoint
     * @param version Version of a custom Endpoint
     */
    createEndpoint(endpointName: string, accountName: string, endpointVersion?: string): Endpoint;
    /**
     * Load an input document from a local path.
     * @param inputPath
     */
    docFromPath(inputPath: string): InputSource;
    /**
     * Load an input document from a base64 encoded string.
     * @param inputString
     * @param filename
     */
    docFromBase64(inputString: string, filename: string): InputSource;
    /**
     * Load an input document from a `stream.Readable` object.
     * @param inputStream
     * @param filename
     */
    docFromStream(inputStream: Readable, filename: string): InputSource;
    /**
     * Load an input document from a bytes string.
     * @param inputBytes
     * @param filename
     */
    docFromBytes(inputBytes: string, filename: string): InputSource;
    /**
     * Load an input document from a URL.
     * @param url
     */
    docFromUrl(url: string): InputSource;
    /**
     * Load an input document from a Buffer.
     * @param buffer
     * @param filename
     */
    docFromBuffer(buffer: Buffer, filename: string): InputSource;
}
